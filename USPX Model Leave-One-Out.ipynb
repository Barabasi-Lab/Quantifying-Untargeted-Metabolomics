{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import prince\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.stats import loguniform\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_objective, plot_histogram\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare USDA and Phenol Expore data\n",
    "uspx_data=pd.read_csv('USPX_features.csv')\n",
    "uspx_data=uspx_data[uspx_data['value']!=0] #Remove rows reporting 0 concentration\n",
    "uspx_data=uspx_data.reset_index()\n",
    "uspx_data=uspx_data.drop(columns=['index'])\n",
    "\n",
    "#Split data\n",
    "uspx_comp_ids=uspx_data[['row_id','comp_name','InChIKey']] #Chemical Identifiers\n",
    "Slbl=uspx_data[['row_id','Cvariable','C_Label','F_Label']] #Labels for Stratifying Folds\n",
    "uspx_props=uspx_data[['MW','C','logP','logS','HBI','NCA','NPSA','C_Label']] #Property Features\n",
    "uspx_phylo=uspx_data[['class','order','family','genus','F_Label']] #Phylogenetic Features\n",
    "uspx_resp=uspx_data[['row_id','logvalue']] #Response Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Principal Components for Compounds and Foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge all chemical property lists of all datasets\n",
    "uspx_props=uspx_props.drop_duplicates() #Remove duplicate compounds\n",
    "uspx_props=uspx_props.reset_index(drop=True)\n",
    "Clbl=pd.DataFrame(uspx_props['C_Label']) #Create Compound Label list of merged dataset\n",
    "uspx_props=uspx_props.drop(columns=['C_Label']) #Drop label column for input into PCA\n",
    "\n",
    "#Merge all phylogenetic lists of all datasets\n",
    "uspx_phylo=uspx_phylo.drop_duplicates() #Remove dulplicate foods\n",
    "uspx_phylo=uspx_phylo.reset_index(drop=True)\n",
    "Flbl=pd.DataFrame(uspx_phylo['F_Label']) #Create Phylogenetic Label list of merged dataset\n",
    "uspx_phylo=uspx_phylo.drop(columns=['F_Label']) #Drop label column for input into MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Principle Components of property features for merged dataset\n",
    "pca=PCA(n_components=7)\n",
    "pcc_df=pca.fit_transform(uspx_props) #Find principal components for the chemical properties\n",
    "pcc_df=pd.DataFrame(data=pcc_df,columns=['PCC1','PCC2','PCC3','PCC4','PCC5','PCC6','PCC7'])\n",
    "print('prop explained:',pca.explained_variance_ratio_)\n",
    "\n",
    "#Find Components of phylogenetic features for merged dataset\n",
    "mca=prince.MCA(n_components=13)\n",
    "mca.fit(uspx_phylo)\n",
    "pcp_df=mca.transform(uspx_phylo) #Find principal components for the phylogenetic tree\n",
    "pcp_df.columns=['PCP1','PCP2','PCP3','PCP4','PCP5','PCP6','PCP7','PCP8','PCP9','PCP10','PCP11','PCP12','PCP13']\n",
    "print('pt explained:',mca.total_inertia_)\n",
    "print(sum(mca.explained_inertia_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data out of Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a USDA Phenol Explorer Training Dataset from the PCA and MCA analysis components\n",
    "n1=len(uspx_data)\n",
    "xx=np.linspace(0,(n1*1),(n1*1)+1)\n",
    "USPX=pd.DataFrame(columns=['PCC1','PCC2','PCC3','PCC4','PCP1','PCP2','PCP3','PCP4','PCP5','PCP6','PCP7','PCP8','PCP9','PCP10','PCP11','PCP12','PCP13'], index=xx)\n",
    "\n",
    "for h in uspx_data.index:\n",
    "    #Find property component features for each row in USPX data\n",
    "    S1=Clbl.loc[Clbl['C_Label']==uspx_data['C_Label'][h]]\n",
    "    USPX.loc[h,('PCC1','PCC2','PCC3','PCC4')]=[pcc_df.loc[S1.index[0],'PCC1'],pcc_df.loc[S1.index[0],'PCC2'],pcc_df.loc[S1.index[0],'PCC3'],pcc_df.loc[S1.index[0],'PCC4']]\n",
    "    \n",
    "    #Find phylogenetic component features for each row in USPX data\n",
    "    S1=Flbl.loc[Flbl['F_Label']==uspx_data['F_Label'][h]]\n",
    "    USPX.loc[h,('PCP1','PCP2','PCP3','PCP4','PCP5','PCP6','PCP7','PCP8','PCP9','PCP10','PCP11','PCP12','PCP13')]=[pcp_df.loc[S1.index[0],'PCP1'],pcp_df.loc[S1.index[0],'PCP2'],pcp_df.loc[S1.index[0],'PCP3'],pcp_df.loc[S1.index[0],'PCP4'],pcp_df.loc[S1.index[0],'PCP5'],pcp_df.loc[S1.index[0],'PCP6'],pcp_df.loc[S1.index[0],'PCP7'],pcp_df.loc[S1.index[0],'PCP8'],pcp_df.loc[S1.index[0],'PCP9'],pcp_df.loc[S1.index[0],'PCP10'],pcp_df.loc[S1.index[0],'PCP11'],pcp_df.loc[S1.index[0],'PCP12'],pcp_df.loc[S1.index[0],'PCP13']]\n",
    "USPX=USPX.dropna()\n",
    "USPX=USPX.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter Optimization\n",
    "X=USPX\n",
    "Y=uspx_resp['logvalue']\n",
    "\n",
    "#Stratified folds by Chemical Classes\n",
    "y=Slbl['Cvariable']\n",
    "skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "cvf=skf.split(X,y)\n",
    "\n",
    "#Find optimization start time\n",
    "t=time.time()\n",
    "\n",
    "#Bayesian optimizer and parameters\n",
    "opt=BayesSearchCV(\n",
    "    estimator=GradientBoostingRegressor(),\n",
    "    search_spaces={'max_depth':(3,10),\n",
    "    'max_leaf_nodes':(2,50),\n",
    "    'learning_rate':(0.01,1.0,'log-uniform'),\n",
    "    'n_estimators':(10,200)},\n",
    "    n_iter=100,\n",
    "    verbose=0,\n",
    "    cv=cvf\n",
    ")\n",
    "opt.fit(X,np.ravel(Y))\n",
    "\n",
    "#Duration of optimization and best fit hyperparameters\n",
    "print('Elapsed: %s' % (time.time()-t))\n",
    "print(\"score: %s\" % opt.best_score_)\n",
    "print(opt.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#All Hyperparameter Optimization Results\n",
    "pd.DataFrame(opt.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opt.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.DataFrame(opt.cv_results_)\n",
    "d.loc[d['mean_test_score']==opt.best_score_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl=GradientBoostingRegressor(\n",
    "    n_estimators=opt.best_params_['n_estimators'],\n",
    "    max_leaf_nodes=opt.best_params_['max_leaf_nodes'],\n",
    "    learning_rate=opt.best_params_['learning_rate'],\n",
    "    max_depth=opt.best_params_['max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create Save File\n",
    "n1=len(USPX)\n",
    "xx=np.linspace(0,(n1*1),(n1*1)+1)\n",
    "pairs=pd.DataFrame(columns=['row_id','real','pred','Fold','AFold','MSE'], index=xx)\n",
    "\n",
    "r=0\n",
    "t=time.time()\n",
    "T=[]\n",
    "for h in USPX.index:\n",
    "    t1=time.time()\n",
    "    pairs.row_id[r]=uspx_comp_ids['row_id'][h]\n",
    "    \n",
    "    # Select compound\n",
    "    Test_X=USPX.iloc[[h]]\n",
    "    Test_Y=uspx_resp.iloc[[h]]\n",
    "    Test_Y=Test_Y['logvalue']\n",
    "    \n",
    "    # Drop selected compound from training \n",
    "    Train_X=USPX.drop(h)\n",
    "    Train_Y=uspx_resp.drop(h)\n",
    "    Train_Y=Train_Y['logvalue']\n",
    "    \n",
    "    # Predict concentration for select compound\n",
    "    mdl.fit(Train_X,np.ravel(Train_Y))\n",
    "    mse=mean_squared_error(np.ravel(Test_Y),mdl.predict(Test_X))\n",
    "    prd=mdl.predict(Test_X)[0]\n",
    "    rl=float(Test_Y[h])\n",
    "    pairs.real[r]=rl\n",
    "    pairs.pred[r]=prd\n",
    "    pairs.MSE[r]=mse\n",
    "    \n",
    "    # Calculate fold change and absolute fold change\n",
    "    if rl<prd:\n",
    "        pairs.Fold[r]=np.exp(prd)/np.exp(rl)\n",
    "        pairs.AFold[r]=np.exp(prd)/np.exp(rl)\n",
    "    else:\n",
    "        pairs.Fold[r]=np.exp(rl)/np.exp(prd)*-1\n",
    "        pairs.AFold[r]=np.exp(rl)/np.exp(prd)\n",
    "    r=r+1\n",
    "    \n",
    "    T.append(time.time()-t1)\n",
    "    print('Percent Complete:',\"{:.2%}\".format(h/len(USPX.index)),'Estimated Time Remaining=', 'hrs:',round(((len(USPX.index)-h)*np.mean(T))/60/60,3), 'min:',round(((len(USPX.index)-h)*np.mean(T))/60,3),end=\"\\r\")\n",
    "    \n",
    "    #Saves a file after every 1000 for insurance\n",
    "    if h>0:\n",
    "        check=h/1000\n",
    "        if (check-int(check)==0)==True:\n",
    "            filename='USPX_iter_'+str(h)+'.csv'\n",
    "            pairs.to_csv(filename,sep=',')\n",
    "    \n",
    "print('Elapsed: %s' % (time.time()-t))\n",
    "pairs=pairs.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.to_csv('USPX-predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Fold Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Save File\n",
    "n1=30\n",
    "xx=np.linspace(0,(n1*1),(n1*1)+1)\n",
    "FDP=pd.DataFrame(columns=['FD','Percent'], index=xx)\n",
    "\n",
    "# Find percent of Fold Changes (FC) at each integer threshold of FC\n",
    "for h in range(1,n1+1):\n",
    "    cnt=0\n",
    "    for j in pairs['AFold']:\n",
    "        if j<h:\n",
    "            cnt=cnt+1\n",
    "    \n",
    "    per=cnt/len(pairs)\n",
    "    FDP.FD[h]=h\n",
    "    FDP.Percent[h]=per\n",
    "FDP=FDP.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Stats on Leave one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean MSE: \",np.mean(pairs['MSE']))\n",
    "print(\"std MSE: \",np.std(pairs['MSE']))\n",
    "print(\"Median MSE: \",np.median(pairs['MSE']))\n",
    "print(\"Mean FD: \",np.mean(pairs['AFold']))\n",
    "print(\"std FD: \",np.std(pairs['AFold']))\n",
    "print(\"Median FD: \",np.median(pairs['AFold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
